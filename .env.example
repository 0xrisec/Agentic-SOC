# LLM Provider Configuration
# Supported providers: openai, gemini
LLM_PROVIDER=gemini

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4-turbo-preview

# Gemini Configuration
GEMINI_API_KEY=1
GEMINI_MODEL=gemini-2.5-flash

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=true

# Logging
LOG_LEVEL=INFO

# Agent Configuration
TRIAGE_TEMPERATURE=0.1
INVESTIGATION_TEMPERATURE=0.3
DECISION_TEMPERATURE=0.1
RESPONSE_TEMPERATURE=0.2

# Alert Processing
MAX_CONCURRENT_ALERTS=5
ALERT_TIMEOUT_SECONDS=300

LLM_TIMEOUT_SECONDS=2
USE_MOCK_DATA_ON_ERROR=True